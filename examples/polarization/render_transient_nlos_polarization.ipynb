{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating NLOS captures with mitransient\n",
    "\n",
    "## Overview\n",
    "<div class=\"admonition important alert alert-block alert-success\">\n",
    "\n",
    "ðŸš€ **You will learn how to:**\n",
    "\n",
    "<ul>\n",
    "  <li>Import `mitransient` and configure it for NLOS scenes</li>\n",
    "  <li>Setup a NLOS scene, including the relay wall, laser, camera and hidden geometry</li>\n",
    "  <li>Visualize the output capture</li>\n",
    "</ul>\n",
    "\n",
    "</div>\n",
    "\n",
    "In this tutorial, you will use mitransient to simulate a non-line-of-sight (NLOS) scene with mitransient. If you are not familiar, NLOS imaging algorithm use indirect light scattered in the scene to reconstruct hidden objects, for example around a corner. For this example, we will target a Z-shaped geometry defined in `Z.obj`. The scene's camera will not directly capture light from the Z object, but instead capture indirect light that has bounced on a rectangular *relay wall*. The key elements in the scene will be:\n",
    "1. The **hidden Z-shaped object**\n",
    "2. The **relay wall**, defined with the `rectangle` plugin, which contains a `nlos_capture_meter` (a **sensor** to measure indirect light)\n",
    "3. A **laser source** that illuminates the relay wall. We will show how to position and orient this source so that it illuinates points on the relay wall\n",
    "\n",
    "### Importing `mitransient`\n",
    "Before importing `mitransient`, you need to import Mitsuba 3 and set a variant (here we use `llvm_ad_rgb`). Only if you want to use more variants, you will need to compile Mitsuba 3 (not `mitransient`) yourself. And you will need to add the compilation folder to the `PYTHONPATH` (see the commented code for how to do that).\n",
    "\n",
    "<div class=\"admonition important alert alert-block alert-warning\">\n",
    "\n",
    "For many cases, `mitransient` requires the use of a `llvm_*` or `cuda_*` variant, so we don't recommend using `scalar_rgb`. It will work with any `llvm_*` or `cuda_*` variant, and for most use cases `llvm_ad_rgb` or `cuda_ad_rgb` is enough. **Maybe if you plan to do NLOS simulations it can be worth to do `llvm_mono` or `cuda_mono`, which only uses one wavelength instead of three RGB channels, and thus is faster.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have compiled Mitsuba 3 yourself, you will need to specify the path\n",
    "# to the compilation folder\n",
    "# import sys\n",
    "# sys.path.insert(0, '<mitsuba-path>/mitsuba3/build/python')\n",
    "import mitsuba as mi\n",
    "# To set a variant, you need to have set it in the mitsuba.conf file\n",
    "# https://mitsuba.readthedocs.io/en/latest/src/key_topics/variants.html\n",
    "mi.set_variant('cuda_ad_mono_polarized')\n",
    "\n",
    "import mitransient as mitr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the NLOS scene\n",
    "\n",
    "In this tutorial you will learn how to prepare a NLOS scene using our library. We will do it following a programmatically way defining each component independently. Here we do it with `mi.load_dict`, but we also provide a `nlos_Z.xml` file which can be loaded with `mi.load_file` and gives the same results. Note that the conversion from XML and dictionaries is fairly straightforward.\n",
    "\n",
    "<div class=\"admonition important alert alert-block alert-success\">\n",
    "\n",
    "If you want to learn more about the parameters of each plugin (geometry, emitter, transient_film, etc.), you can check [Mitsuba 3's documentation](https://mitsuba.readthedocs.io/en/stable/src/plugin_reference.html), and our documentation ([integrators](https://mitransient.readthedocs.io/en/latest/generated/plugin_reference/section_integrators.html), [films](https://mitransient.readthedocs.io/en/latest/generated/plugin_reference/section_films.html), [sensors](https://mitransient.readthedocs.io/en/latest/generated/plugin_reference/section_sensors.html), [other functions](https://mitransient.readthedocs.io/en/latest/src/other.html))\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the geometry of the hidden scene\n",
    "gold_bsdf = {\n",
    "    \"type\": \"roughconductor\",\n",
    "    \"distribution\": \"ggx\",\n",
    "    \"material\": \"Au\",\n",
    "    \"alpha_u\": 0.9,\n",
    "    \"alpha_v\": 0.9\n",
    "}\n",
    "\n",
    "geometry = mi.load_dict(\n",
    "    {\n",
    "        \"type\": \"obj\",\n",
    "        \"filename\": \"./Z.obj\",\n",
    "        \"to_world\": mi.ScalarTransform4f().translate([0.0, 0.0, 1.0]),\n",
    "        \"bsdf\": gold_bsdf,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Load the emitter (laser) of the scene\n",
    "emitter = mi.load_dict(\n",
    "    {\n",
    "        \"type\": \"projector\",\n",
    "        \"irradiance\": 100.0,\n",
    "        \"fov\": 0.2,\n",
    "        \"to_world\": mi.ScalarTransform4f().translate([0.0, 0.0, 0.25]),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Define the transient film which store all the data\n",
    "transient_film = mi.load_dict(\n",
    "    {\n",
    "        \"type\": \"transient_hdr_film\",\n",
    "        \"width\": 64,\n",
    "        \"height\": 64,\n",
    "        \"temporal_bins\": 300,\n",
    "        \"bin_width_opl\": 0.006,\n",
    "        \"start_opl\": 1.85,\n",
    "        \"rfilter\": {\"type\": \"box\"},\n",
    "    }\n",
    ")\n",
    "\n",
    "# Define the sensor of the scene\n",
    "nlos_sensor = mi.load_dict(\n",
    "    {\n",
    "        \"type\": \"nlos_capture_meter\",\n",
    "        \"sampler\": {\"type\": \"independent\", \"sample_count\": 65_536},\n",
    "        \"account_first_and_last_bounces\": False,\n",
    "        # This config sets the nlos_sensor in front of the relay wall, not realistic for\n",
    "        # NLOS setups, but it is easier for polarization visualization\n",
    "        \"sensor_origin\": mi.ScalarPoint3f(0.0, 0.0, 0.25),\n",
    "        \"transient_film\": transient_film,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Load the relay wall. This includes the custom \"nlos_capture_meter\" sensor which allows to setup measure points directly on the shape and importance sample paths going through the relay wall.\n",
    "relay_wall = mi.load_dict(\n",
    "    {\n",
    "        \"type\": \"rectangle\",\n",
    "        \"bsdf\": gold_bsdf,\n",
    "        \"nlos_sensor\": nlos_sensor,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Finally load the integrator\n",
    "integrator = mi.load_dict(\n",
    "    {\n",
    "        \"type\": \"transient_nlos_path\",\n",
    "        \"nlos_laser_sampling\": True,\n",
    "        \"nlos_hidden_geometry_sampling\": True,\n",
    "        \"nlos_hidden_geometry_sampling_do_rroulette\": False,\n",
    "        \"temporal_filter\": \"box\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the final scene\n",
    "scene = mi.load_dict({\n",
    "    'type' : 'scene',\n",
    "    'geometry' : geometry,\n",
    "    'emitter' : emitter,\n",
    "    'relay_wall' : relay_wall,\n",
    "    'integrator' : integrator\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we focus the emitter to irradiate one specific pixel of the \"relay wall\"\n",
    "pixel = mi.Point2f(32, 32)\n",
    "mitr.nlos.focus_emitter_at_relay_wall_pixel(pixel, relay_wall, emitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render the scene in steady and transient domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_steady, data_transient = mi.render(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition important alert alert-block alert-warning\">\n",
    "Mitsuba 3 and `mitransient` work with Dr.JIT, which has lazy evaluation.\n",
    "That means the actual image/video will not be computed until you use it.\n",
    "As such, this cell should take &lt;1s to execute\n",
    "</div>\n",
    "\n",
    "The result is:\n",
    "1) A steady state image `data_steady` with dimensions (width, height, channels)\n",
    "2) A transient image `data_transient` with dimensions (width, height, time, channels)\n",
    "\n",
    "`data_steady` would be the result of a conventional (non-transient) render i.e. `data_steady = data_transient.sum(axis=2)`\n",
    "\n",
    "### Visualize the steady and transient image\n",
    "We provide different functions so you can visualize your data in a Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the transient image\n",
    "\n",
    "The important part for NLOS imaging is `data_transient`, which contains the time-resolved indirect illumination. Here we show how to visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data_transient is a 4D array represented as a Dr.JIT's TensorXf class.\n",
    "It is very similar to a numpy array (in fact, you can convert between\n",
    "the two by using np.array(data_transient))\n",
    "'''\n",
    "print(data_transient.__class__.__name__)\n",
    "# The channels represent (x, y, time, rgb)\n",
    "print(data_transient.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot radiance at one pixel over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i, j = 11, 11\n",
    "\n",
    "# There are two main ways of plotting data_transient\n",
    "# The first one is to plot a single pixel's time-resolved response\n",
    "plt.plot(np.array(data_transient)[i, j, :, 0])\n",
    "plt.xlabel('Time index')\n",
    "plt.ylabel(f'Captured radiance at pixel ({i}, {j})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transient-polarization visualization\n",
    "\n",
    "S1 and S2 share colorbar.\n",
    "\n",
    "The other plots are those proposed by Wilkie and Weidlich [2013], commonly used in polarization research (see Baek et al. [2020] teaser)\n",
    "\n",
    "[Wilkie2013] Alexander Wilkie and Andrea Weidlich. 2010. A standardised polarisation visualisation for images. In Proceedings of the 26th Spring Conference on Computer Graphics (SCCG '10). Association for Computing Machinery, New York, NY, USA, 43â€“50. https://doi.org/10.1145/1925059.1925070\n",
    "\n",
    "[Baek2020] Seung-Hwan Baek, Tizian Zeltner, Hyun Jin Ku, Inseung Hwang, Xin Tong, Wenzel Jakob, and Min H. Kim. 2020. Image-based acquisition and modeling of polarimetric reflectance. ACM Trans. Graph. 39, 4, Article 139 (August 2020), 14 pages. https://doi.org/10.1145/3386569.3392387\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transient_np = np.array(data_transient)\n",
    "print(f'{data_transient_np.shape=}')\n",
    "dop = mitr.vis.degree_of_polarization(data_transient_np)\n",
    "dop, aolp, aolp_scaled, top, chirality = mitr.vis.polarization_generate_false_color(data_transient_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mitr.vis.show_video_polarized(data_transient_np[:, :, :, :], dop, aolp, top, chirality, save_path='video.mp4', display_method=mitr.vis.DisplayMethod.ShowVideo, show_false_color=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mitransientpol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
